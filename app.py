# app.py - Streamlit (correcci√≥n KeyError y EDA completo listo para Render)
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import ks_2samp

st.set_page_config(page_title="EDA PRSA - Dongsi", layout="wide")
st.markdown("""
    <style>
    body { background-color: #0f1720; color: #ffffff; }
    .block-container { padding: 1rem; }
    .analysis-box { background: rgba(255,255,255,0.03); padding:10px; border-radius:8px; }
    </style>
""", unsafe_allow_html=True)

# -------------------------
# Load & normalize columns
# -------------------------
@st.cache_data
def load_data(path="PRSA_Data_Dongsi_20130301-20170228.csv"):
    df = pd.read_csv(path)
    # normalize column names: strip, lower, replace dots with underscore, replace spaces
    df.columns = df.columns.str.strip().str.lower().str.replace('.', '_', regex=False).str.replace(' ', '_', regex=False)
    # build datetime if year/month/day/hour present
    cols = df.columns
    if set(['year','month','day','hour']).issubset(cols):
        try:
            df['datetime'] = pd.to_datetime(dict(year=df['year'].astype(int),
                                                 month=df['month'].astype(int),
                                                 day=df['day'].astype(int),
                                                 hour=df['hour'].astype(int)))
        except Exception:
            # fallback: try combining as string
            df['datetime'] = pd.to_datetime(df[['year','month','day','hour']].astype(str).agg(' '.join, axis=1), errors='coerce')
    else:
        # if there's a date-like column try to parse it
        date_cols = [c for c in cols if 'date' in c]
        if date_cols:
            df['datetime'] = pd.to_datetime(df[date_cols[0]], errors='coerce')
    return df

try:
    df = load_data()
except FileNotFoundError:
    st.error("No se encontr√≥ 'PRSA_Data_Dongsi_20130301-20170228.csv' en la ra√≠z. S√∫belo y recarga la app.")
    st.stop()

# -------------------------
# Prepare variable lists
# -------------------------
all_cols = df.columns.tolist()
# candidate pollutant names and meteorological names (normalized)
candidates = {
    'pollutants': ['pm2_5','pm10','so2','no2','co','o3'],
    'mets': ['temp','pres','dewp','rain','wspm','humi','iws','is','ir','wd','cbwd']
}
pollutants = [c for c in candidates['pollutants'] if c in all_cols]
mets = [c for c in candidates['mets'] if c in all_cols]
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

# keep original copy for before-imputation comparisons
df_original = df.copy()
df_imputed = None  # will be set after imputing

# -------------------------
# Sidebar controls - CORREGIDO
# -------------------------
st.sidebar.header("Controles")
tab_choice = st.sidebar.selectbox("Ir a secci√≥n", [
    "Resumen", "Distribuciones", "Series temporales",
    "Correlaciones", "Faltantes", "Bivariado", "Conclusiones"
])

# -------------------------
# Imputaci√≥n autom√°tica - DECISI√ìN T√âCNICA
# -------------------------
# Explicaci√≥n de por qu√© elegimos interpolaci√≥n temporal:
# 1. Los datos son de series de tiempo (fechas consecutivas)
# 2. La interpolaci√≥n temporal preserva la estructura temporal
# 3. Es m√°s apropiado que mean/median para datos secuenciales

def impute_dataframe(df_in):
    """Aplica imputaci√≥n autom√°tica usando interpolaci√≥n temporal"""
    df_out = df_in.copy()
    numcols = df_out.select_dtypes(include=[np.number]).columns.tolist()
    
    if 'datetime' in df_out.columns and df_out['datetime'].notna().any():
        df_out = df_out.sort_values('datetime')
        df_out = df_out.set_index('datetime')
        df_out[numcols] = df_out[numcols].interpolate(method='time', limit_direction='both')
        df_out = df_out.reset_index()
        # Fill any remaining missing values
        df_out[numcols] = df_out[numcols].ffill().bfill()
    else:
        # Fallback: interpolaci√≥n lineal si no hay datetime
        df_out[numcols] = df_out[numcols].interpolate().ffill().bfill()
    
    return df_out

# Aplicar imputaci√≥n autom√°ticamente
df_imputed = impute_dataframe(df_original)

# -------------------------
# Heur√≠stica tipo de ausencia
# -------------------------
def classify_missing_type(col_name, df_obj):
    p = df_obj[col_name].isna().mean()
    if p == 0:
        return "Sin faltantes"
    
    # Obtener columnas num√©ricas excluyendo la columna actual si es num√©rica
    numeric = df_obj.select_dtypes(include=[np.number])
    
    # Si la columna actual es num√©rica, excluirla del an√°lisis de correlaci√≥n
    if col_name in numeric.columns:
        numeric = numeric.drop(columns=[col_name])
    
    # Si no hay columnas num√©ricas restantes, usar heur√≠stica simple
    if numeric.shape[1] == 0:
        return "MCAR" if p < 0.2 else "MNAR"
    
    # Calcular correlaci√≥n entre indicador de missing y otras variables num√©ricas
    indicator = df_obj[col_name].isna().astype(int)
    cors = numeric.apply(lambda x: indicator.corr(x) if x.notna().any() else np.nan)
    max_abs_corr = cors.abs().max(skipna=True)
    
    if pd.isna(max_abs_corr):
        return "MCAR"
    if max_abs_corr > 0.3:
        return "MAR"
    if p > 0.20:
        return "MNAR"
    return "MCAR"

# -------------------------
# Sections (tabs)
# -------------------------
def show_summary():
    st.header("Resumen del dataset")
    st.markdown(f"- Filas: **{df_original.shape[0]}**  ‚Ä¢  Columnas: **{df_original.shape[1]}**")
    st.markdown(f"- Variables num√©ricas detectadas: **{len(numeric_cols)}**")
    if 'station' in df_original.columns:
        st.markdown(f"- Estaci√≥n: **{df_original['station'].unique().tolist()}**")
    st.write("Primeras filas:")
    st.dataframe(df_original.head())

    # monthly trend for pollutants if exist
    if 'datetime' in df_original.columns and len(pollutants) > 0:
        dfm = df_original.set_index('datetime').resample('M')[pollutants].mean().reset_index()
        fig = px.line(dfm, x='datetime', y=pollutants, title="Promedio mensual - contaminantes")
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("No hay columna 'datetime' o no se detectaron contaminantes para serie mensual.")

def show_distributions():
    st.header("Distribuciones (univariadas)")
    vars_for_select = numeric_cols.copy()
    if not vars_for_select:
        st.warning("No se encontraron variables num√©ricas.")
        return
    sel = st.selectbox("Selecciona variable num√©rica", vars_for_select)
    col = sel
    data = df_imputed[col].dropna()
    fig = px.histogram(data, x=data, nbins=40, title=f"Histograma de {col}", marginal="box")
    st.plotly_chart(fig, use_container_width=True)
    st.write("Estad√≠sticos b√°sicos:")
    st.table(df_imputed[col].describe().to_frame().T)

def show_time_series():
    st.header("Series temporales")
    if 'datetime' not in df_imputed.columns:
        st.warning("No se detect√≥ columna de fecha/hora (`datetime`).")
        return
    vars_ts = numeric_cols
    sel = st.selectbox("Selecciona variable para serie temporal", vars_ts, index=0)
    dfts = df_imputed.set_index('datetime').resample('D')[sel].mean().reset_index()
    fig = px.line(dfts, x='datetime', y=sel, title=f"Serie diaria de {sel}")
    st.plotly_chart(fig, use_container_width=True)

def show_correlations():
    st.header("Matriz de correlaci√≥n (s√≥lo columnas disponibles)")
    # choose reasonable subset for correlation (use intersection)
    candidate_corr = ['pm2_5','pm10','so2','no2','co','o3','temp','pres','dewp','wspm','iws','is','ir','humi','rain']
    cols_corr = [c for c in candidate_corr if c in df_imputed.columns]
    if not cols_corr:
        # fallback to numeric cols
        cols_corr = numeric_cols
    if not cols_corr:
        st.warning("No hay columnas para correlaci√≥n.")
        return
    corr = df_imputed[cols_corr].corr()
    fig = px.imshow(corr, text_auto=True, title="Correlaci√≥n entre variables")
    st.plotly_chart(fig, use_container_width=True)

def show_missing():
    st.header("An√°lisis de valores faltantes")
    # Before imputation (original)
    st.subheader("Antes de imputar (original)")
    miss_before = df_original.isna().sum()
    miss_before = miss_before[miss_before > 0].sort_values(ascending=False)
    if not miss_before.empty:
        st.dataframe(miss_before.to_frame("n_missing"))
        # CORRECCI√ìN: Crear el DataFrame correctamente
        miss_before_df = miss_before.reset_index()
        miss_before_df.columns = ['variable', 'missing']  # Renombrar directamente las columnas
        fig = px.bar(miss_before_df, x='variable', y='missing', title="Faltantes antes")
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.success("No hay faltantes en el dataset original.")

    # classify types
    st.subheader("Tipo de ausencia (heur√≠stica)")
    types = {col: classify_missing_type(col, df_original) for col in df_original.columns if df_original[col].isna().sum() > 0}
    if types:
        st.dataframe(pd.DataFrame(list(types.items()), columns=['variable','tipo']).set_index('variable'))
    else:
        st.info("No hay columnas con faltantes para clasificar.")

    # After imputation (current df_imputed)
    st.subheader("Despu√©s de imputar (actual)")
    miss_after = df_imputed.isna().sum()
    miss_after = miss_after[miss_after > 0].sort_values(ascending=False)
    if not miss_after.empty:
        st.dataframe(miss_after.to_frame("n_missing"))
        # CORRECCI√ìN: Crear el DataFrame correctamente
        miss_after_df = miss_after.reset_index()
        miss_after_df.columns = ['variable', 'missing']  # Renombrar directamente las columnas
        fig2 = px.bar(miss_after_df, x='variable', y='missing', title="Faltantes despu√©s")
        st.plotly_chart(fig2, use_container_width=True)
    else:
        st.success("No quedan faltantes tras la imputaci√≥n seleccionada.")

    # KS tests for variables that had missing originally
    st.subheader("Prueba KS (antes vs despu√©s) ‚Äî variables que tuvieron NA")
    had_na = [c for c in df_original.columns if df_original[c].isna().sum() > 0 and c in numeric_cols]
    if not had_na:
        st.info("No hay variables num√©ricas con NA en el original para comparar.")
    else:
        ks_rows = []
        for c in had_na:
            orig_vals = df_original[c].dropna().values
            new_vals = df_imputed[c].dropna().values
            if len(orig_vals) < 2 or len(new_vals) < 2:
                ks_rows.append((c, np.nan, np.nan, "insuficientes datos"))
                continue
            try:
                stat, p = ks_2samp(orig_vals, new_vals)
                note = "No cambio significativo" if p > 0.05 else "Cambio significativo"
                ks_rows.append((c, float(stat), float(p), note))
            except Exception as e:
                ks_rows.append((c, np.nan, np.nan, f"error: {e}"))
        ks_df = pd.DataFrame(ks_rows, columns=['variable','ks_stat','pvalue','nota']).set_index('variable')
        st.dataframe(ks_df)

def show_bivariate():
    st.header("An√°lisis bivariado")
    if len(numeric_cols) < 2:
        st.warning("Se requieren al menos dos variables num√©ricas.")
        return
    x = st.selectbox("Variable X", numeric_cols, index=0)
    y = st.selectbox("Variable Y", numeric_cols, index=1)
    plot_type = st.selectbox("Tipo de gr√°fico", ["scatter", "scatter + trendline", "hexbin (dense)"])
    if plot_type == "scatter":
        fig = px.scatter(df_imputed, x=x, y=y, opacity=0.6, title=f"{x} vs {y}")
    elif plot_type == "scatter + trendline":
        fig = px.scatter(df_imputed, x=x, y=y, trendline="lowess", opacity=0.5, title=f"{x} vs {y} (lowess)")
    else:
        # hexbin via plotly densitiy_heatmap
        fig = px.density_heatmap(df_imputed, x=x, y=y, nbinsx=40, nbinsy=40, title=f"Densidad {x} vs {y}")
    st.plotly_chart(fig, use_container_width=True)
    # show correlation
    corr_val = df_imputed[x].corr(df_imputed[y])
    st.write(f"Coeficiente de correlaci√≥n (Pearson) entre **{x}** y **{y}**: **{corr_val:.3f}**")

# -------------------------
# Dispatch according to selection
# -------------------------
if tab_choice == "Resumen":
    show_summary()
elif tab_choice == "Distribuciones":
    show_distributions()
elif tab_choice == "Series temporales":
    show_time_series()
elif tab_choice == "Correlaciones":
    show_correlations()
elif tab_choice == "Faltantes":
    show_missing()
elif tab_choice == "Bivariado":
    show_bivariate()
elif tab_choice == "Conclusiones":
    st.header("Conclusiones")
    st.markdown("""
    ### M√©todo de Imputaci√≥n Seleccionado
    
    **Interpolaci√≥n Temporal** fue el m√©todo elegido porque:
    
    - üìä **Los datos son series temporales** con mediciones consecutivas
    - ‚è±Ô∏è **Preserva la estructura temporal** y patrones estacionales
    - üîÑ **Mantiene la autocorrelaci√≥n** entre observaciones adyacentes
    - üìà **Es m√°s apropiado** que m√©todos como media/mediana para datos secuenciales
    
    ### Otros Hallazgos
    
    - Se normalizaron nombres de columnas para evitar KeyError
    - El an√°lisis muestra faltantes antes/despu√©s con clasificaci√≥n heur√≠stica
    - Pruebas KS verifican que la imputaci√≥n no altera significativamente las distribuciones
    - Dashboard se adapta a las columnas realmente presentes en el dataset
    """)
# Footer
st.markdown("---")
st.caption("App generada por asistente ‚Äî aseg√∫rate que el CSV est√© en la ra√≠z: PRSA_Data_Dongsi_20130301-20170228.csv")




